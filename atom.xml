<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://CCCLL.github.io</id>
    <title>CCCLL</title>
    <updated>2024-02-19T09:26:50.340Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://CCCLL.github.io"/>
    <link rel="self" href="https://CCCLL.github.io/atom.xml"/>
    <logo>https://CCCLL.github.io/images/avatar.png</logo>
    <icon>https://CCCLL.github.io/favicon.ico</icon>
    <rights>All rights reserved 2024, CCCLL</rights>
    <entry>
        <title type="html"><![CDATA[MySQL亿级大表慢查询逐步优化实战]]></title>
        <id>https://CCCLL.github.io/post/mysql-yi-ji-da-biao-man-cha-xun-zhu-bu-you-hua-shi-zhan/</id>
        <link href="https://CCCLL.github.io/post/mysql-yi-ji-da-biao-man-cha-xun-zhu-bu-you-hua-shi-zhan/">
        </link>
        <updated>2024-02-04T11:14:17.000Z</updated>
        <content type="html"><![CDATA[<p><strong>背景</strong>：物联网相关项目。设备对OpenAPI每次的调用情况记录到了MySQL中，在控制台页面做了展示，可根据调用时间的范围（必选条件）、设备ID、API名称等作为条件筛选展示，主要用途是便于排障。</p>
<p><strong>问题</strong>：客户设备数据量较多，造成OpenAPI调用记录表太大，查询很慢，甚至直接卡死。尽管运维同事使用脚本定时删除此表的数据，只保留近一月的数据，一月数据量仍然有三亿多条，还是存在问题。</p>
<p>因为是从前同事手里接手的项目，先看了下程序代码没什么大问题。接下来再看下项目的表结构和SQL有什么可以优化的地方。</p>
<h2 id="第一步-sql和表结构优化">第一步、SQL和表结构优化</h2>
<h3 id="sql优化">SQL优化</h3>
<p><strong>OpenAPI调用记录表现状结构</strong></p>
<pre><code class="language-sql">CREATE TABLE `openapi_log` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `api` varchar(255) NOT NULL DEFAULT '',
  `device_id` varchar(100) DEFAULT '',
  `device_type` varchar(100) DEFAULT '',
  `param` varchar(2048) DEFAULT NULL,
  `result` tinyint(4) NOT NULL,
  `call_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
  `exec_time` bigint(20) NOT NULL,
  `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`),
  KEY `idx_calltime_api` (`call_time`,`api`),
  KEY `idx_calltime_deviceid` (`call_time`,`device_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
</code></pre>
<p><strong>OpenAPI调用记录表现状查询SQL</strong></p>
<pre><code class="language-xml">&lt;select id=&quot;query&quot; resultMap=&quot;BaseResultMap&quot;&gt;
    select
    log.id, log.device_id, log.api, log.param, log.result,log.call_time, log.exec_time,log.create_time,log.update_time
    from openapi_log log
    inner join (select id from openapi_log
    &lt;include refid=&quot;filterSql&quot;/&gt;
    order by call_time desc
    &lt;if test=&quot;limit!=null and skip!=null&quot;&gt;
      limit #{skip},#{limit}
    &lt;/if&gt;
     ) temp on log.id=temp.id
&lt;/select&gt;


  &lt;sql id=&quot;filterSql&quot;&gt;
    &lt;if test=&quot;filter!=null&quot;&gt;
      &lt;where&gt;
        &lt;if test=&quot;filter.deviceId!=null&quot;&gt;
          and device_id =#{filter.device_id}
        &lt;/if&gt;
        &lt;if test=&quot;filter.api!=null&quot;&gt;
          and api=#{filter.api}
        &lt;/if&gt;
        &lt;if test=&quot;filter.callTimeGte!=null and filter.callTimeLte!=null&quot;&gt;
          and call_time &gt;=#{filter.callTimeGte} and call_time &amp;lt;= #{filter.callTimeLte}
        &lt;/if&gt;
      &lt;/where&gt;
    &lt;/if&gt;
  &lt;/sql&gt;
</code></pre>
<p>可以看到上述SQL使用到了子查询，估计前同事是看了阿里巴巴《Java开发手册》中的推荐，见下图<br>
<img src="https://CCCLL.github.io/post-images/1708250444461.png" alt="" loading="lazy"></p>
<p>但是此优化是针对深度分页的状况，在此功能的场景上基本不会深度分页，<strong>非深度分页的状况下，此优化是负优化</strong>。如果项目会有深度分页情形，可在代码层面做判断，深度分页走子查询优化SQL，非深度分页则不走子查询。</p>
<p>以下是测试对比，同样的数据量、非深度分页状况下，分别用了原SQL和去掉子查询的SQL查询详细消耗情况</p>
<p><strong>现状代码SQL 1</strong></p>
<pre><code class="language-sql">select
    log.id, log.device_id, log.api, log.param, log.result,log.call_time, log.exec_time,log.create_time,log.update_time
    from openapi_log log
    inner join (select id from openapi_log_test
    	where
        call_time &gt;= '2026-11-10 10:00:00.000' AND call_time &lt;= '2026-11-10 12:00:00.000'
    	order by call_time desc limit 50,50
     ) temp on log.id=temp.id;
</code></pre>
<p><strong>去掉子查询SQL 2</strong></p>
<pre><code class="language-sql">SELECT
    log.id, log.device_id, log.api, log.param, log.result, log.call_time, log.exec_time, log.create_time, log.update_time
FROM
    openapi_log log
WHERE
    log.call_time &gt;= '2026-11-10 10:00:00.000' AND log.call_time &lt;= '2026-11-10 12:00:00.000'

ORDER BY log.call_time DESC
LIMIT 50, 50;
</code></pre>
<p><strong>1号框为原代码SQL，2号框为去掉子查询后的SQL，可以看到去掉子查询后的SQL查询时间减少 30%。</strong><br>
<img src="https://CCCLL.github.io/post-images/1708250542494.png" alt="" loading="lazy"></p>
<p><strong>原代码SQL的详细时间消耗情况</strong><br>
<img src="https://CCCLL.github.io/post-images/1708250559663.png" alt="" loading="lazy"></p>
<p><strong>去掉子查询SQL的详细时间消耗情况</strong><br>
<img src="https://CCCLL.github.io/post-images/1708250770189.png" alt="" loading="lazy"></p>
<p><strong>结论</strong>：SQL优化后查询时间减少大约30%。经对比可看出由于原代码使用了子查询产生了临时表，所以多了removing tmp table步骤，并且一些步骤需要做两遍，如checking permissions、optimizing、preparing、Sending data等。</p>
<h3 id="表结构优化">表结构优化</h3>
<p>从上文的表结构中可以看到，OpenAPI调用记录表的两个索引都是联合索引，idx_calltime_api和idx_calltime_deviceid。但是考虑到call_time和device_id的离散程度本来就较高，而且发现表的索引占用空间很大，所以考虑只给call_time和device_id列创建两个单列索引。</p>
<p><strong>测试SQL</strong></p>
<pre><code class="language-sql">SELECT
    log.id, log.api,log.`device_id`,log.`device_type`, log.param, log.result, log.call_time, log.exec_time
FROM
    openapi_log_test log USE INDEX (idx_calltime_deviceid)
WHERE
    log.call_time &gt;= '2026-06-01 00:55:58.026' AND log.call_time &lt;= '2026-06-01 22:55:58.026'
    AND log.device_id like '8OIzhN1Fi92z347Xh91GOaomVgEiWLlgefcLddMxq%'
ORDER BY log.call_time DESC
LIMIT 0, 10;

SELECT
    log.id, log.api,log.`device_id`,log.`device_type`, log.param, log.result, log.call_time, log.exec_time
FROM
    openapi_log_test log
WHERE
    log.call_time &gt;= '2026-06-01 00:55:58.026' AND log.call_time &lt;= '2026-06-01 22:55:58.026'
    AND log.device_id like '8OIzhN1Fi92z347Xh91GOaomVgEiWLlgefcLddMxq%'
ORDER BY log.call_time DESC
LIMIT 0, 10;
</code></pre>
<p><strong>对比测试结果</strong></p>
<p><strong>3使用了联合索引，4使用了device_id单列的索引</strong><br>
<img src="https://CCCLL.github.io/post-images/1708250802595.png" alt="" loading="lazy"></p>
<p><strong>联合索引</strong><br>
<img src="https://CCCLL.github.io/post-images/1708250818889.png" alt="" loading="lazy"></p>
<p><strong>单列索引</strong><br>
<img src="https://CCCLL.github.io/post-images/1708250834178.png" alt="" loading="lazy"></p>
<p><strong>结论</strong>：因call_time、device_id离散程度本来就较高，所以只从单列索引中便能获取较高的性能。从使用联合索引查询分析数据来看，联合索引较大，反而在读索引这一步花费了较多时间。</p>
<h2 id="第二步-业务层面优化">第二步、业务层面优化</h2>
<p>做的这些对SQL和表结构的优化，只能算锦上添花但是没有解决真正问题。从测试中可以发现如果查询的数据范围较小即使是3亿多条数据的这种大表查询起来也是很快的，但是当我们把查询的数据范围加大以后便会出现查询变慢甚至卡死的问题。</p>
<p><strong>查询1，范围10个小时</strong></p>
<pre><code class="language-sql">SELECT
    log.id, log.api, log.param, log.result, log.call_time, log.exec_time, log.create_time, log.update_time
FROM
    openapi_log_test log
WHERE
    log.call_time &gt;= '2027-04-10 10:00:00.000' AND log.call_time &lt;= '2027-04-10 20:00:00.000'
    And log.`api`='abc.xxx.xxx'
    
ORDER BY log.call_time DESC
LIMIT 50, 500;  
</code></pre>
<p><strong>查询2，范围14个小时</strong></p>
<pre><code class="language-sql">SELECT
    log.id, log.api, log.param, log.result, log.call_time, log.exec_time, log.create_time, log.update_time
FROM
    openapi_log_test log
WHERE
    log.call_time &gt;= '2027-04-10 10:00:00.000' AND log.call_time &lt;= '2027-04-10 24:00:00.000'
    And log.`api`='abc.xxx.xxx'
    
ORDER BY log.call_time DESC
LIMIT 50, 500;  
</code></pre>
<p><strong>查询1和查询2时间消耗对比</strong><br>
<img src="https://CCCLL.github.io/post-images/1708250853294.png" alt="" loading="lazy"></p>
<p><strong>查询1具体消耗</strong><br>
<img src="https://CCCLL.github.io/post-images/1708250860438.png" alt="" loading="lazy"></p>
<p><strong>查询2具体消耗</strong><br>
<img src="https://CCCLL.github.io/post-images/1708250867326.png" alt="" loading="lazy"></p>
<p><strong>结论</strong>：通过对比可见，当查询范围超过一定临界值时（和内存大小有关），Sending data过程会做大量的Block_ops_in和Block_ops_out。Block_ops_in和Block_ops_out表示块存储设备输入和输出的次数，即从硬盘读取和写入数据的次数。因官方文档并未给出大量Block_ops_in和Block_ops_out原因的详细解释，结合上下文猜测是，因数据量大于内存可用量，会借助硬盘进行内存交换，因此产生大量的硬盘读取和写入。因此导致了查询时间变慢。</p>
<p>因为当在控制台页面查询OpenAPI调用记录时，主要为了排障使用，所以需要查询特定的一条或几条，那么此场景下所需的时间范围就一定不会太大，所以可以<strong>限制查询数据的时间范围</strong>，从业务层面避免查询过慢的情况。</p>
<h2 id="第三步-分表">第三步、分表</h2>
<p>上文有提到有使用脚本定时删除此表的数据，只保留近一月的数据。但是这样会有一些副作用：</p>
<ol>
<li>数据删除会影响数据库性能，引发慢sql，多张表并行删除，数据库压力会更大。</li>
<li>频繁删除数据，会产生数据库碎片，影响数据库性能，引发慢SQL。</li>
</ol>
<p>还有就是上文提到的限制查询数据范围来解决慢查询问题，只适合特定的业务场景。比如在我负责的产品中有个功能，根据前一天的数据，来生成日报展示。如果限制查询时间，那只能在代码层面分多次查询，较不合理。</p>
<p>所以针对上述问题，针对大表可做分表。还以上文的OpenAPI调用记录表为例，按日期对表进行横向拆分，实现让系统每周生成一张周期表，表内只存近一周的数据，规避单表过大带来的风险。</p>
<h3 id="分表方案选型">分表方案选型</h3>
<p>经调研，考虑2种分表方案：ShardingSphere、利用Mybatis自带的拦截器特性。</p>
<p>经过对比后，决定采用Mybatis拦截器来实现分表，原因如下：</p>
<ol>
<li>JAVA生态中很常用的分表框架是ShardingSphere，虽然功能强大，但需要一定的接入成本，并且很多功能暂时用不上。</li>
<li>系统本身已经在使用Mybatis了，只需要添加一个mybaits拦截器，把SQL表名替换为新的周期表就可以了，没有接入新框架的成本，开发成本也不高。<br>
<img src="https://CCCLL.github.io/post-images/1708251137474.png" alt="" loading="lazy"></li>
</ol>
<h3 id="实现代码">实现代码</h3>
<p>详细代码以上传到Github：<a href="https://github.com/CCCLL/sharding-demo">https://github.com/CCCLL/sharding-demo</a></p>
<p><strong>分表配置对象</strong></p>
<pre><code class="language-java">import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

import java.time.LocalDate;

/**
 * @Author: CCCLL
 */
@Data
@AllArgsConstructor
@NoArgsConstructor
public class ShardingProperty {
    // 分表周期天数
    private Integer days;
    // 分表开始日期，需要用这个日期计算周期表名
    private LocalDate beginDate;
    // 需要分表的表名
    private String tableName;
}
</code></pre>
<p><strong>分表配置类</strong></p>
<pre><code class="language-java">import java.time.LocalDate;
import java.time.format.DateTimeFormatter;
import java.util.concurrent.ConcurrentHashMap;

/**
 * @Author: CCCLL
 */
public class ShardingPropertyConfig {

    //此配置可存入数据库或配置中心
    public static final ConcurrentHashMap&lt;String, ShardingProperty&gt; SHARDING_TABLE = new ConcurrentHashMap&lt;&gt;();

    static {
        ShardingProperty apiLogShardingProperty = new ShardingProperty(3, LocalDate.parse(&quot;20240201&quot;, DateTimeFormatter.ofPattern(&quot;yyyyMMdd&quot;)), &quot;openapi_log_test&quot;);
        ShardingProperty ggaLogShardingProperty = new ShardingProperty(7, LocalDate.parse(&quot;20240101&quot;, DateTimeFormatter.ofPattern(&quot;yyyyMMdd&quot;)), &quot;gga_log&quot;);

        SHARDING_TABLE.put(apiLogShardingProperty.getTableName(), apiLogShardingProperty);
        SHARDING_TABLE.put(ggaLogShardingProperty.getTableName(), ggaLogShardingProperty);
    }
}
</code></pre>
<p><strong>Mapper</strong></p>
<pre><code class="language-java">import org.apache.ibatis.annotations.Mapper;
import org.apache.ibatis.annotations.Param;
import org.example.sharding.Sharding;
import org.example.sharding.ShardingRedundancy;

import java.util.List;

/**
 * @Author: CCCLL
 */
@Mapper
@Sharding
public interface OpenApiLogMapper {

    int bulkInsert(List&lt;OpenApiLog&gt; logs);

    @ShardingRedundancy
    int bulkInsertRedundancy(List&lt;OpenApiLog&gt; logs);

    List&lt;OpenApiLog&gt; query(@Param(&quot;filter&quot;) OpenapiLogQuery filter);
}
</code></pre>
<p><strong>MyBatis拦截器</strong></p>
<pre><code class="language-java">import com.sun.istack.internal.NotNull;
import lombok.extern.slf4j.Slf4j;
import org.apache.commons.lang3.StringUtils;
import org.apache.ibatis.executor.statement.StatementHandler;
import org.apache.ibatis.mapping.BoundSql;
import org.apache.ibatis.mapping.MappedStatement;
import org.apache.ibatis.plugin.*;
import org.apache.ibatis.reflection.DefaultReflectorFactory;
import org.apache.ibatis.reflection.MetaObject;
import org.apache.ibatis.reflection.ReflectorFactory;
import org.apache.ibatis.reflection.factory.DefaultObjectFactory;
import org.apache.ibatis.reflection.factory.ObjectFactory;
import org.apache.ibatis.reflection.wrapper.DefaultObjectWrapperFactory;
import org.apache.ibatis.reflection.wrapper.ObjectWrapperFactory;
import org.springframework.stereotype.Component;

import java.lang.reflect.Method;
import java.sql.Connection;
import java.time.LocalDate;
import java.time.format.DateTimeFormatter;
import java.time.temporal.ChronoUnit;
import java.util.Properties;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

/**
 * @Author: CCCLL
 */
@Slf4j
@Component
@Intercepts({@Signature(type = StatementHandler.class, method = &quot;prepare&quot;, args = {Connection.class, Integer.class})})
public class ShardingTableInterceptor implements Interceptor {
    private static final ObjectFactory DEFAULT_OBJECT_FACTORY = new DefaultObjectFactory();
    private static final ObjectWrapperFactory DEFAULT_OBJECT_WRAPPER_FACTORY = new DefaultObjectWrapperFactory();
    private static final ReflectorFactory DEFAULT_REFLECTOR_FACTORY = new DefaultReflectorFactory();
    private static final String MAPPED_STATEMENT = &quot;delegate.mappedStatement&quot;;

    private static final String BOUND_SQL = &quot;delegate.boundSql&quot;;
    private static final String ORIGIN_BOUND_SQL = &quot;delegate.boundSql.sql&quot;;
    private static final DateTimeFormatter FORMATTER = DateTimeFormatter.ofPattern(&quot;yyyyMMdd&quot;);

    private Pattern pattern = Pattern.compile(&quot;(from|into|update)[\\s]{1,}(\\w{1,})&quot;, Pattern.CASE_INSENSITIVE);


    @Override
    public Object intercept(Invocation invocation) throws Throwable {

        StatementHandler statementHandler = (StatementHandler) invocation.getTarget();
        MetaObject metaStatementHandler = MetaObject.forObject(statementHandler, DEFAULT_OBJECT_FACTORY, DEFAULT_OBJECT_WRAPPER_FACTORY, DEFAULT_REFLECTOR_FACTORY);
        // 根据mapper的注解判断是否进行分表操作
        MappedStatement mappedStatement = (MappedStatement) metaStatementHandler.getValue(MAPPED_STATEMENT);
        String id = mappedStatement.getId();
        String className = id.substring(0, id.lastIndexOf(&quot;.&quot;));
        Class&lt;?&gt; clazz = Class.forName(className);
        if (!clazz.isAnnotationPresent(Sharding.class)) {
            return invocation.proceed();
        }

        // 获取SQL
        BoundSql boundSql = (BoundSql) metaStatementHandler.getValue(BOUND_SQL);
        String originSql = (String) metaStatementHandler.getValue(ORIGIN_BOUND_SQL);
        if (StringUtils.isBlank(originSql)) {
            return invocation.proceed();
        }

        // 获取表名
        Matcher matcher = pattern.matcher(boundSql.getSql());
        String tableName;
        if (matcher.find()) {
            tableName = matcher.group(2).trim();
        } else {
            return invocation.proceed();
        }
        ShardingProperty shardingProperty = ShardingPropertyConfig.SHARDING_TABLE.get(tableName);
        if (shardingProperty == null) {
            return invocation.proceed();
        }

        // 获取新表名
        Method[] methods = clazz.getMethods();
        String methodName = id.substring(id.lastIndexOf(&quot;.&quot;) + 1);
        LocalDate tableNameDate = LocalDate.now();
        for (Method method : methods) {
            if (methodName.equals(method.getName())) {
                if (method.isAnnotationPresent(ShardingRedundancy.class)) {
                    tableNameDate = LocalDate.now().plusDays(shardingProperty.getDays());
                }
            }

        }
        String shardingTable = getCurrentShardingTable(shardingProperty, tableNameDate);
        if (shardingTable == null) {
            return invocation.proceed();
        }

        // 重构SQL，替换表名
        String rebuildSql = boundSql.getSql().replace(shardingProperty.getTableName(), shardingTable);
        metaStatementHandler.setValue(ORIGIN_BOUND_SQL, rebuildSql);
        log.info(&quot;originSql:[{}], rebuildSql:[{}]&quot;, originSql, rebuildSql);
        return invocation.proceed();
    }

    @Override
    public Object plugin(Object target) {
        if (target instanceof StatementHandler) {
            return Plugin.wrap(target, this);
        }
        return target;
    }

    @Override
    public void setProperties(Properties properties) {
    }

    public static String getCurrentShardingTable(@NotNull ShardingProperty shardingProperty, @NotNull LocalDate now) {
        String tableName = shardingProperty.getTableName();
        Integer days = shardingProperty.getDays();
        LocalDate beginDate = shardingProperty.getBeginDate();


        if (now.isBefore(beginDate)) {
            return null;
        }

        LocalDate intervalStartDate = getIntervalStartDate(now, beginDate, days);
        LocalDate intervalEndDate = intervalStartDate.plusDays(days - 1);
        return tableName + &quot;_&quot; + intervalStartDate.format(FORMATTER) + &quot;_&quot; + intervalEndDate.format(FORMATTER);
    }

    public static LocalDate getIntervalStartDate(LocalDate targetDate, LocalDate startDate, int days) {
        long daysBetween = ChronoUnit.DAYS.between(startDate, targetDate);
        long interval = daysBetween / days;
        return startDate.plusDays(interval * days);
    }
}
</code></pre>
<h3 id="临界点数据不连续问题">临界点数据不连续问题</h3>
<p>分表方案有1个难点需要解决：<strong>周期临界点数据不连续</strong>。举例：假设要对openapi_log（OpenAPI调用记录表）大表进行横向分表，每周一张表，分表明细可看下面表格。</p>
<table>
<thead>
<tr>
<th>第一周（openapi_log_20240201_20240207）</th>
<th>第二周（openapi_log_20240208_20240214）</th>
<th>第三周（openapi_log_20240215_20240221）</th>
</tr>
</thead>
<tbody>
<tr>
<td>2月1号～2月7号的数据</td>
<td>2月8号～2月14号的数据</td>
<td>2月15号～2月21号的数据</td>
</tr>
</tbody>
</table>
<p>2月8号就是分表临界点，8号需要切换到第二周的表，但8号0点刚切换的时候，表内没有任何数据，这时如果需要查近一天或最近几个小时的数据是查不到的。</p>
<p>我决定采用数据冗余的方式来解决这个痛点。每个周期表都冗余一份上个周期的数据，用双倍数据量实现数据滑动的效果，效果见下面表格。</p>
<table>
<thead>
<tr>
<th>第一周（openapi_log_20240201_20240207）</th>
<th>第二周（openapi_log_20240208_20240214）</th>
<th>第三周（openapi_log_20240215_20240221）</th>
</tr>
</thead>
<tbody>
<tr>
<td>1月25号～1月31号的数据</td>
<td>2月1号～2月7号的数据</td>
<td>2月8号～2月14号的数据</td>
</tr>
<tr>
<td>2月1号～2月7号的数据</td>
<td>2月8号～2月14号的数据</td>
<td>2月15号～2月21号的数据</td>
</tr>
</tbody>
</table>
<p><strong>注：表格内第一行数据就是冗余的上个周期表的数据。</strong></p>
<p>思路有了，接下来就要考虑怎么实现<strong>双写（数据冗余到下个周期表）</strong>，较为简单的方案是执行两次SQL，但是要注意在MyBatis拦截器替换表名时需做区分。此方案实现简单，成本小。但是因为是串行的执行了两次SQL，有一定性能损耗。第二种方案是监听增量binlog，可以使用cannal，性能较好。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[使用JProfiler排查程序问题实践]]></title>
        <id>https://CCCLL.github.io/post/shi-yong-jprofiler-pai-cha-cheng-xu-wen-ti-shi-jian/</id>
        <link href="https://CCCLL.github.io/post/shi-yong-jprofiler-pai-cha-cheng-xu-wen-ti-shi-jian/">
        </link>
        <updated>2024-01-28T04:17:05.000Z</updated>
        <content type="html"><![CDATA[<h2 id="基础">基础</h2>
<figure data-type="image" tabindex="1"><img src="https://CCCLL.github.io/post-images/1706415637854.png" alt="" loading="lazy"></figure>
<p><strong>Retained size</strong><br>
对象的保留大小（<strong>Retained size</strong>）是其浅层大小加上只能从该对象直接或间接访问的对象的浅层大小。换句话说，保留大小表示当收集该对象时垃圾收集器将释放的内存量。<br>
<strong>Shallow size</strong> <br>
对象的浅层大小（<strong>Shallow size</strong>）是分配用于存储对象本身的内存量，不考虑引用的对象。常规（非数组）对象的浅层大小取决于其字段的数量和类型。数组的浅层大小取决于数组长度及其元素的类型（对象、基本类型）。一组对象的浅层大小表示该组中所有对象的浅层大小之和。</p>
<h3 id="outgoing-references">Outgoing references</h3>
<figure data-type="image" tabindex="2"><img src="https://CCCLL.github.io/post-images/1706963743640.png" alt="" loading="lazy"></figure>
<p>Outgoing references 表示：展示此对象的字段引用的对象。</p>
<h3 id="incoming-references">Incoming references</h3>
<figure data-type="image" tabindex="3"><img src="https://CCCLL.github.io/post-images/1706963788356.png" alt="" loading="lazy"></figure>
<p>Incoming references 表示：展示引用了此对象的对象。</p>
<h2 id="查找类实例对象">查找类实例对象</h2>
<h3 id="根据类名搜索">根据类名搜索</h3>
<figure data-type="image" tabindex="4"><img src="https://CCCLL.github.io/post-images/1706963950173.png" alt="" loading="lazy"></figure>
<h3 id="实例对象筛选">实例对象筛选</h3>
<p>如果某个类的实例对象有很多，比如Map类中的Entry对象、Session对象、用户对象等。我们要排查问题时要找到指定的实例对象，来查看指定对象里成员变量的详细值。只用类名筛选实例对象太多，较难找到。可使用实例对象中字符串成员变量，进而找到指定实例对象。例如Entry对象的key、Session对象的session id，用户对象的用户名等。</p>
<p>1、首先搜索String类，双击java.lang.String进入字符串类对象的集合<br>
<img src="https://CCCLL.github.io/post-images/1706964158819.png" alt="" loading="lazy"><br>
<img src="https://CCCLL.github.io/post-images/1706964262232.png" alt="" loading="lazy"></p>
<p>2、使用Apply filter 的 By restricting the selected value 选项<br>
<img src="https://CCCLL.github.io/post-images/1706964335632.png" alt="" loading="lazy"><br>
<img src="https://CCCLL.github.io/post-images/1706964376223.png" alt="" loading="lazy"></p>
<p>3、使用 The result of the toString(method satisfies the condition:  功能<br>
<img src="https://CCCLL.github.io/post-images/1706964410931.png" alt="" loading="lazy"></p>
<p>4、字符串匹配方式有包含、头匹配、尾匹配、正则表达式匹配，还可选择是否忽略大小写<br>
<img src="https://CCCLL.github.io/post-images/1706964444138.png" alt="" loading="lazy"></p>
<p>5、输入要查找的字符串对象的值（目的是找到spacex.select.local这个字符串对应的SpacexProperty对象，查看SpacexProperty对象的value成员变量的值），对应的类代码如下<br>
<img src="https://CCCLL.github.io/post-images/1706964609344.png" alt="" loading="lazy"><br>
<img src="https://CCCLL.github.io/post-images/1706964635983.png" alt="" loading="lazy"></p>
<p>6、Outgoing references表示此字符串对象持有的成员变量，需改成Incoming references表示持有此字符串对象的实例对象<br>
<img src="https://CCCLL.github.io/post-images/1706964672311.png" alt="" loading="lazy"><br>
<img src="https://CCCLL.github.io/post-images/1706964766044.png" alt="" loading="lazy"></p>
<p>7、我们在这里就找到了spacex.select.local这个字符串对应的SpacexProperty对象<br>
<img src="https://CCCLL.github.io/post-images/1706964892690.png" alt="" loading="lazy"></p>
<p>8、我们右击此对象，选择Use Selected Objects<br>
<img src="https://CCCLL.github.io/post-images/1706964970937.png" alt="" loading="lazy"></p>
<p>9、选择Use Selected Objects后，并将查看模式改为Outgoing references，就可以看到此配置的值<br>
<img src="https://CCCLL.github.io/post-images/1706965069110.png" alt="" loading="lazy"></p>
<h2 id="查看实例对象的静态成员变量">查看实例对象的静态成员变量</h2>
<p>1、首先找到指定的实例对象，使用类名搜索<br>
<img src="https://CCCLL.github.io/post-images/1706965180300.png" alt="" loading="lazy"></p>
<p>2、找到指定实例后，右键选择Use Selected java.lang.Class Objects<br>
<img src="https://CCCLL.github.io/post-images/1706965244804.png" alt="" loading="lazy"></p>
<p>3、即可查看此实例静态对象详情<br>
<img src="https://CCCLL.github.io/post-images/1706965322925.png" alt="" loading="lazy"><br>
实例对应类的代码如下<br>
<img src="https://CCCLL.github.io/post-images/1706965386474.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[关于git rebase和git merge]]></title>
        <id>https://CCCLL.github.io/post/guan-yu-git-rebase-he-git-merge/</id>
        <link href="https://CCCLL.github.io/post/guan-yu-git-rebase-he-git-merge/">
        </link>
        <updated>2024-01-22T12:49:37.000Z</updated>
        <content type="html"><![CDATA[<p>场景：从a分支的a1节点checkout出一个新分支b，然后在b分支上进行了多次修改、新增的commit。与此同时a分支也进行了多次修改、新增的commit。现在想把b分支上的修改和新增合并到a分支上，应该怎么操作？</p>
<pre><code>          b1---b2---b3---b4---b5 b
         /
    a0---a1---a2---a3---a4---a5---a6---a7 a
</code></pre>
<p>你可以使用 <strong><code>git rebase</code></strong> 或 <strong><code>git merge</code></strong> 将分支 <code>b</code> 上的commit合并到分支 <code>a</code> 上。下面是两种方法的步骤：</p>
<h2 id="合并代码"><strong>合并代码</strong></h2>
<h3 id="方法一使用-git-rebase推荐"><strong>方法一：使用 <code>git rebase</code>（推荐）</strong></h3>
<ol>
<li>
<p><strong>切换到分支 <code>a</code>：</strong></p>
<pre><code class="language-bash">git checkout a
</code></pre>
</li>
<li>
<p><strong>执行 rebase 操作：</strong></p>
<pre><code class="language-bash">git rebase b
</code></pre>
<p>这将会将分支 <code>a</code> 上的修改应用到分支 <code>b</code> 上，然后将分支 <code>b</code> 上的修改逐个应用到分支 <code>a</code> 上。在这个过程中，如果有冲突，你需要解决冲突并继续 rebase。</p>
</li>
<li>
<p><strong>（可选）推送更新到远程仓库：</strong></p>
<p>如果分支 <code>a</code>有对应的远程分支，需要使用强制推送：</p>
<p><code>git rebase</code> 能确保提交历史的清晰，但在 <code>git push</code> 时可能会遇到一些问题，因为你的本地分支已经和远程分支的历史不一致了。简单来说，你的本地分支&quot;领先&quot;了远程分支。因此，我们不能像平常那样直接git push，需要使用以下命令：</p>
<pre><code class="language-bash">git push -f origin your_branch_name
</code></pre>
<p>这里的 <code>-f</code> 或 <code>--force</code> 参数会强制推送你的本地分支到远程，即使它会导致远程仓库的提交历史改变。</p>
<p>但请注意，<code>--force</code> 选项会覆盖远程仓库上的所有更改，所以只有当你确保没有其他人在这个分支上工作，或者其他人已经知道你要这么做，并且保存了他们的更改在别的地方的情况下，才使用这个命令。知道什么时候使用 <code>--force</code> 这个选项，是一个重要的版本控制技能。</p>
<h3 id="方法二使用-git-merge"><strong>方法二：使用 <code>git merge</code></strong></h3>
<ol>
<li>
<p><strong>切换到分支 <code>a</code>：</strong></p>
<pre><code class="language-bash">git checkout a
</code></pre>
</li>
<li>
<p><strong>执行 merge 操作：</strong></p>
<pre><code class="language-bash">git merge b
</code></pre>
<p>这将会将分支 <strong><code>b</code></strong> 上的修改合并到分支 <strong><code>a</code></strong> 上。如果有冲突，你需要解决冲突并commit你的合并修改，完成合并。</p>
</li>
<li>
<p><strong>（可选）推送更新到远程仓库：</strong></p>
<p>如果分支 <strong><code>a</code></strong> 是已经推送到远程仓库的分支，你可能需要推送更新（和**<code>rebase</code>**不同的是，这里不需要强制推送）：</p>
<pre><code class="language-bash">git push origin a
</code></pre>
</li>
</ol>
<p>选择使用 <strong><code>git rebase</code></strong> 还是 <strong><code>git merge</code></strong> 取决于你的团队工作流和个人偏好。<strong><code>git rebase</code></strong> 会产生一个更线性的提交历史，而 <strong><code>git merge</code></strong> 保留了每个分支上的独立提交。</p>
<h2 id="使用git-merge和git-rebase遇到的问题"><strong>使用<code>git merge</code>和<code>git rebase</code>遇到的问题</strong></h2>
<p>如果 git rebase 和 git merge都使用过的话，会发现使用git rebase比使用git merge，需要更多次的冲突合并，这是什么原因那？</p>
<p><code>git rebase</code> 产生更多的冲突的原因有几个：</p>
<ol>
<li>
<p><strong>Reapply 修改：</strong></p>
<p><code>git rebase</code> 是通过逐个重新应用提交来进行的，而 <code>git merge</code> 是通过创建一个新的合并提交来整合两个分支的更改。在 <code>rebase</code> 过程中，每个提交都可能导致冲突，而在 <code>merge</code> 过程中，只有一个合并提交需要解决冲突。</p>
</li>
<li>
<p><strong>线性提交历史：</strong></p>
<p><code>git rebase</code> 生成的提交历史是线性的，每个提交都构建在前一个提交之上。这意味着如果有多个分支同时在目标分支上进行 <code>rebase</code>，可能会有更多的冲突需要解决，因为每个提交都可能与目标分支的最新提交发生冲突。</p>
</li>
<li>
<p><strong>历史分叉的影响：</strong></p>
<p>如果分支 <code>a</code> 和分支 <code>b</code> 基于相同的父提交，并且两者都进行了多次修改，当你尝试将分支 <code>b</code> 上的修改通过 <code>rebase</code> 应用到分支 <code>a</code> 时，可能会导致较早的提交已经包含了在分支 <code>b</code> 上进行的某些修改，从而引发冲突。</p>
</li>
</ol>
<h2 id="总结"><strong>总结</strong></h2>
<p>尽管 <code>git rebase</code> 可能会产生更多的冲突，但它有助于保持提交历史的线性和整洁。不过如果两个分支之间差别的commit较多，个人推荐使用<code>git merge</code>，因为<code>git rebase</code> 针对多次commit的多次冲突解决，很有可能因疏忽大意导致合并结果不正确，而<code>git merge</code>只需一次冲突解决，降低人为因素导致错误的概率。</p>
</li>
</ol>
]]></content>
    </entry>
</feed>